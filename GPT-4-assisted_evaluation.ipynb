{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c85b2-fff8-4af5-82fc-0df31e24ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionGraph:\n",
    "    def __init__(self):\n",
    "        self.graph = {}  # Initialize an empty dictionary to hold the adjacency list.\n",
    "\n",
    "    def add_path(self, words, synonym):\n",
    "        # Add a path of words that leads to a list of synonyms.\n",
    "        if len(words) == 1:\n",
    "            # If there's only one word, associate it directly with the synonym.\n",
    "            word = words[0]\n",
    "            if word not in self.graph:\n",
    "                self.graph[word] = {'': [synonym]}\n",
    "            else:\n",
    "                self.graph[word][''] = self.graph[word].get('', []) + [synonym]\n",
    "        else:\n",
    "            current = words[0]\n",
    "            for next_word in words[1:-1]:\n",
    "                if current not in self.graph:\n",
    "                    self.graph[current] = {next_word: []}\n",
    "                elif next_word not in self.graph[current]:\n",
    "                    self.graph[current][next_word] = []\n",
    "                current = next_word\n",
    "\n",
    "            # Add the synonym for the last word in the path.\n",
    "            if current not in self.graph:\n",
    "                self.graph[current] = {words[-1]: [synonym]}\n",
    "            else:\n",
    "                self.graph[current][words[-1]] = self.graph[current].get(words[-1], []) + [synonym]\n",
    "\n",
    "    def is_synonym(self, word_list, goal_word):\n",
    "        # Determine if the word list forms a path that is synonymous with the goal word.\n",
    "        if len(word_list) == 1:\n",
    "            # If there's only one word, check if it's associated with the goal word.\n",
    "            return goal_word in self.graph.get(word_list[0], {}).get('', [])\n",
    "        else:\n",
    "            current = word_list[0]\n",
    "            for word in word_list[1:]:\n",
    "                if current in self.graph and word in self.graph[current]:\n",
    "                    current = word\n",
    "                else:\n",
    "                    return False  # Return False if no path matches the sequence.\n",
    "\n",
    "            # Check if the last word's synonym list contains the goal word.\n",
    "            return goal_word in self.graph.get(word_list[-2], {}).get(word_list[-1], [])\n",
    "        \n",
    "        \n",
    "def save_graph(graph, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(graph, file)\n",
    "\n",
    "def load_graph(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33f2f0-f7cd-45a9-98c1-1b5b4b55e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectGraph:\n",
    "    def __init__(self):\n",
    "        self.graph = {}  # Initialize an empty dictionary to hold the adjacency list.\n",
    "\n",
    "    def add_path(self, words, synonym):\n",
    "        # Add a path of words that leads to a list of synonyms.\n",
    "        if len(words) == 1:\n",
    "            # If there's only one word, associate it directly with the synonym.\n",
    "            word = words[0]\n",
    "            if word not in self.graph:\n",
    "                self.graph[word] = {'': [synonym]}\n",
    "            else:\n",
    "                self.graph[word][''] = self.graph[word].get('', []) + [synonym]\n",
    "        else:\n",
    "            current = words[0]\n",
    "            for next_word in words[1:-1]:\n",
    "                if current not in self.graph:\n",
    "                    self.graph[current] = {next_word: []}\n",
    "                elif next_word not in self.graph[current]:\n",
    "                    self.graph[current][next_word] = []\n",
    "                current = next_word\n",
    "\n",
    "            # Add the synonym for the last word in the path.\n",
    "            if current not in self.graph:\n",
    "                self.graph[current] = {words[-1]: [synonym]}\n",
    "            else:\n",
    "                self.graph[current][words[-1]] = self.graph[current].get(words[-1], []) + [synonym]\n",
    "\n",
    "    def is_synonym(self, word_list, goal_word):\n",
    "        # Determine if the word list forms a path that is synonymous with the goal word.\n",
    "        if len(word_list) == 1:\n",
    "            # If there's only one word, check if it's associated with the goal word.\n",
    "            return goal_word in self.graph.get(word_list[0], {}).get('', [])\n",
    "        else:\n",
    "            current = word_list[0]\n",
    "            for word in word_list[1:]:\n",
    "                if current in self.graph and word in self.graph[current]:\n",
    "                    current = word\n",
    "                else:\n",
    "                    return False  # Return False if no path matches the sequence.\n",
    "\n",
    "            # Check if the last word's synonym list contains the goal word.\n",
    "            return goal_word in self.graph.get(word_list[-2], {}).get(word_list[-1], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115ca4a-a83d-47ea-8038-208dc2d5592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = ' ' # your key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae6e98-8319-44ec-a1aa-859f8086f840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f46f4555-216f-4cf3-ac5c-0bd9fa6d16fe",
   "metadata": {},
   "source": [
    "## Generate keywords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5c63e-e33e-4df2-bcff-42fbe98281a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dl_description.csv'\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e829a8-37a8-4d6d-8822-5ebe14a6e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, gt_des in zip(df['image_name'], df['description']):\n",
    "    base_name = image[:-4]\n",
    "    gpt_des_pth = '' # your AI-generated txt file path\n",
    "    if os.path.exists(gpt_des_pth):\n",
    "        if not os.path.exists('dl_eval/{}.txt'.format(base_name)): # set your keywords list file pth\n",
    "            with open(gpt_des_pth, 'r') as txt_file:\n",
    "                gpt_des = txt_file.read().strip()\n",
    "\n",
    "            messages = [\n",
    "                    {\"role\": \"user\", \"content\": []}\n",
    "                ]\n",
    "\n",
    "            messages[0][\"content\"].append({\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"I will provide you two paragraphs. The first paragraph is human-composed and the second paragraph is generated by AI models. I want to evaluate the hallucination in the second paragraph. Please extract the object and action words or phrases from the following text. The objects should have a tangible meaning and consist of no more than two words; non-tangible objects should not be extracted. The action words or phrases should only relate to the extracted objects. Also, you must convert the corresponding actions to their complete root form. Then, for the final answer, please examine 4 lists and must transfer the synonyms in 4 lists into the same word. Please directly output the final object and action lists in two paragraphs, respectively as in the form in the example below without any justifications or intermediate steps.\\nHere is an example:\\n1. The sequence of images captures a dog's cautious interaction with a metal toy inside a house. The dog appears wary and maintains a distance from the unfamiliar object, barking to express its disapproval and possibly intimidation. As the toy moves, the dog's reaction is to bark and lean backward, showing a clear sign of being unsettled by the toy's motion. When the toy momentarily ceases movement, the dog also stops, remaining alert and attentive. At the end of the image, when the toy comes to a halt, the dog looks up, still processing the strange encounter with the inanimate object.\\n2. The image is a collage of multiple pictures featuring two dogs playing with a toy alligator. The dogs are in various positions, with some of them standing on the toy alligator, while others are interacting with it in different ways. The collage captures the dogs' playfulness and excitement as they engage with the toy alligator.\\nThe lists are\\nObject list 1: [dog, toy, house]\\nAction list 1: [interaction, bark, express intimidation, move, lean backward, stop, look up]\\nObject list 2: [dog, toy]\\nAction list 2: [play, stand, interaction]\\nHere is the paragraph:\\n1. {}\\n2. {}\\nThe lists are:\".format(gt_des, gpt_des)})\n",
    "            response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-4-1106-preview\",  # or \n",
    "                    messages=messages,\n",
    "                    temperature=0,\n",
    "                    max_tokens=1000\n",
    "                )\n",
    "            res = response.choices[0][\"message\"]['content']\n",
    "            with open('dl_eval/{}.txt'.format(base_name), 'w') as file:\n",
    "                file.write(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7cef7b-1482-4333-8255-6805fcdb6062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e5869e6-4809-444f-921c-04d4b1e4737a",
   "metadata": {},
   "source": [
    "## Behavior evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501945cf-72a8-4385-ad94-bd9008d87f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_graph = load_graph('dl_action_graph_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65cdcb-dc51-4e59-8383-c1a89d7cb935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_replace_action_synonyms(action1, action2, graph):\n",
    "    tmp_action=action1.copy()\n",
    "    result = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < len(action2) and len(tmp_action) > 0:\n",
    "        # Check for single-word synonyms\n",
    "        k=len(tmp_action)\n",
    "        for j, action in enumerate(tmp_action):\n",
    "            if graph.is_synonym([action2[i]], tmp_action[j]):\n",
    "                result.append(tmp_action[j])\n",
    "                i += 1\n",
    "                tmp_action.pop(j)\n",
    "                break\n",
    "                \n",
    "            if i + 1 < len(action2):\n",
    "                if graph.is_synonym([action2[i], action2[i + 1]], tmp_action[j]):\n",
    "                    result.append(tmp_action[j])\n",
    "                    i += 2  \n",
    "                    tmp_action.pop(j)\n",
    "                    break\n",
    "            j+=1\n",
    "\n",
    "        if k==len(tmp_action):\n",
    "            result.append(action2[i])\n",
    "            i += 1\n",
    "    \n",
    "    if i < len(action2):\n",
    "        result.append(item for item in action2[i:])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17c23fe-fb28-4832-8b8a-dc6ad4f6936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_re = []\n",
    "a_pre = []\n",
    "a_f1 = []\n",
    "for image in df['image_name']:\n",
    "    base_name = image[:-4]\n",
    "    pth = 'dl_eval/{}.txt'.format(base_name)\n",
    "    if os.path.exists(pth):\n",
    "        #print(base_name)\n",
    "        with open(pth, 'r') as txt_file:\n",
    "            gpt_des = txt_file.read().strip()\n",
    "        filtered_list = [element for element in gpt_des.split('\\n') if element]\n",
    "        extracted_lists = {}\n",
    "        for item in filtered_list:\n",
    "            key, value = item.split(': ')\n",
    "            value = value.strip('[]')\n",
    "            elements = [element.strip() for element in value.split(',')]\n",
    "\n",
    "            extracted_lists[key] = elements\n",
    "        a_reference_list = extracted_lists[\"Action list 1\"]\n",
    "        a_prediction_list = extracted_lists[\"Action list 2\"]\n",
    "\n",
    "        a_pred_sym_list = find_and_replace_action_synonyms(a_reference_list, a_prediction_list, action_graph)\n",
    "        a_tp = len(set(a_reference_list) & set(a_pred_sym_list))  \n",
    "        a_fp = len(set(a_pred_sym_list) - set(a_reference_list))  \n",
    "        a_fn = len(set(a_reference_list) - set(a_pred_sym_list))  \n",
    "\n",
    "        a_recall = a_tp / (a_tp + a_fn) if (a_tp + a_fn) != 0 else 0\n",
    "        a_precision = a_tp / (a_tp + a_fp) if (a_tp + a_fp) != 0 else 0\n",
    "\n",
    "        a_f1_score = 2 * (a_precision * a_recall) / (a_precision + a_recall) if (a_precision + a_recall) != 0 else 0\n",
    "\n",
    "        a_re.append(a_recall)\n",
    "        a_pre.append(a_precision)\n",
    "        a_f1.append(a_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793f126-50fb-4c86-a765-b2e9012b3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(a_re)), np.mean(np.array(a_pre)), np.mean(np.array(a_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42716585-36e7-4844-94b2-d41e450d72eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b621ce1-adc9-4442-a0d9-4c3c99da15dd",
   "metadata": {},
   "source": [
    "## Object evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9331f3a1-5b0e-4d55-8bdf-62bf72c0ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_graph = load_graph('dl_object_graph_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de87b57-e9ec-41ef-abc6-af09b842c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_replace_object_synonyms(action1, action2, graph):\n",
    "    # Initialize the result list with Action2\n",
    "    tmp_action=action1.copy()\n",
    "    result = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < len(action2) and len(tmp_action) > 0:\n",
    "        # Check for single-word synonyms\n",
    "        k=len(tmp_action)\n",
    "        for j, action in enumerate(tmp_action):\n",
    "            if graph.is_synonym([action2[i]], tmp_action[j]):\n",
    "                result.append(tmp_action[j])\n",
    "                i += 1\n",
    "                tmp_action.pop(j)\n",
    "                break\n",
    "            j+=1\n",
    "\n",
    "        # If no synonym found, keep the original word\n",
    "        if k==len(tmp_action):\n",
    "            result.append(action2[i])\n",
    "            i += 1\n",
    "    \n",
    "    if i < len(action2):\n",
    "        result.append(item for item in action2[i:])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a198e2-9cce-44ba-a179-4b0bd15d1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_re = []\n",
    "o_pre = []\n",
    "o_f1 = []\n",
    "for image in df['image_name']:\n",
    "    base_name = image[:-4]\n",
    "    pth = 'dl_eval/{}.txt'.format(base_name)\n",
    "    if os.path.exists(pth):\n",
    "        # print(base_name)\n",
    "        with open(pth, 'r') as txt_file:\n",
    "            gpt_des = txt_file.read().strip()\n",
    "        filtered_list = [element for element in gpt_des.split('\\n') if element]\n",
    "        extracted_lists = {}\n",
    "        for item in filtered_list:\n",
    "            key, value = item.split(': ')\n",
    "            value = value.strip('[]')\n",
    "            elements = [element.strip() for element in value.split(',')]\n",
    "\n",
    "            extracted_lists[key] = elements\n",
    "        o_reference_list = extracted_lists[\"Object list 1\"]\n",
    "        o_prediction_list = extracted_lists[\"Object list 2\"]\n",
    "\n",
    "        o_pred_sym_list = find_and_replace_object_synonyms(o_reference_list, o_prediction_list, object_graph)\n",
    "        \n",
    "        #print(o_reference_list)\n",
    "        #print(o_prediction_list)\n",
    "        #print(o_pred_sym_list)\n",
    "        o_tp = len(set(o_reference_list) & set(o_pred_sym_list))  \n",
    "        o_fp = len(set(o_pred_sym_list) - set(o_reference_list))  \n",
    "        o_fn = len(set(o_reference_list) - set(o_pred_sym_list))  \n",
    "\n",
    "        o_recall = o_tp / (o_tp + o_fn) if (o_tp + o_fn) != 0 else 0\n",
    "        o_precision = o_tp / (o_tp + o_fp) if (o_tp + o_fp) != 0 else 0\n",
    "\n",
    "        o_f1_score = 2 * (o_precision * o_recall) / (o_precision + o_recall) if (o_precision + o_recall) != 0 else 0\n",
    "\n",
    "        o_re.append(o_recall)\n",
    "        o_pre.append(o_precision)\n",
    "        o_f1.append(o_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ec27b-7edb-44c7-89e2-5b664de124fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(o_re)), np.mean(np.array(o_pre)), np.mean(np.array(o_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
